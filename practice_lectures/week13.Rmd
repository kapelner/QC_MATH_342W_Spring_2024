---
title: "Practice Lectures Week 12 MATH 342W Queens College"
author: "Professor Adam Kapelner"
date: "May 9, 2022"
---




#RF with many features

How about RF?

```{r}
rf_mod = YARF(data.frame(X_train), y_train, num_trees = 500, calculate_oob_error = FALSE)
rmse_rf = sd(y_test - predict(rf_mod, data.frame(X_test)))

cat("RF advantage over OLS:", round((rmse_ols - rmse_rf) / rmse_ols * 100, 1), "%\n")
```

Takes a very long time to build - why? Amazingly, RF does very well. Why? How it able to not get confused by the junk features? It might be because the real features have a slight SSE edge. I think RF will do poorly if p > n. Maybe a lab exercise?

How about just the RF on the lasso-picked variables? We can delete the intercept since RF doesn't need it.

```{r}
variables_selected = names(b_lasso[b_lasso != 0])
variables_selected = variables_selected[-1]
X_train_sub = data.frame(X_train)[, variables_selected]
X_test_sub = data.frame(X_test)[, variables_selected]

rf_mod = YARF(X_train_sub, y_train, num_trees = 500, mtry = 2, calculate_oob_error = FALSE)
rmse_rf = sd(y_test - predict(rf_mod, X_test_sub))

cat("RF var selected advantage over OLS:", round((rmse_ols - rmse_rf) / rmse_ols * 100, 1), "%\n")
```

Why is that better than lasso? Because lasso is linear and in RF you get a bit of juice from the non-linearities and interactions. Why is it very slightly better than RF on the full data set? Because variable selection is a good "pre-step" to do sometimes. This is why in the real world there's usually a "pipeline" that cleans data, then variable selects, then fits model then validates.


# Asymmetric Cost Models in Trees and RF

Let's load up the adult dataset where the response is 1 if the person makes more than $50K per year and 0 if they make less than $50K per year.

```{r}
rm(list = ls())
options(java.parameters = "-Xmx4000m")
pacman::p_load(YARF)
pacman::p_load_gh("coatless/ucidata")
data(adult)
adult %<>% 
  na.omit #kill any observations with missingness
```

Let's use samples of 2,000 to run experiments:

```{r}
train_size = 2000
train_indices = sample(1 : nrow(adult), train_size)
adult_train = adult[train_indices, ]
y_train = adult_train$income
X_train = adult_train %>% select(-income)
test_indices = setdiff(1 : nrow(adult), train_indices)
adult_test = adult[test_indices, ]
y_test = adult_test$income
X_test = adult_test %>% select(-income)
```

What does the $y$'s look like?

```{r}
table(y_train)
```

Very imbalanced. This would off-the-bat make y=0 the default.

Now make a regular RF and look at the oob confusion table and FDR and FOR:

```{r}
num_trees = 500
yarf_mod = YARF(X_train, y_train, num_trees = num_trees, calculate_oob_error = FALSE)
y_hat_test = predict(yarf_mod, X_test)
oos_confusion = table(y_test, y_hat_test)
oos_confusion
cat("FDR =", oos_confusion[1, 2] / sum(oos_confusion[, 2]), "\n")
cat("FOR =", oos_confusion[2, 1] / sum(oos_confusion[, 1]), "\n")
```

High FDR rate and low FOR rate. Let's try to change this and reduce the FDR by oversampling 0's.

```{r}
idx_0 = which(y_train == "<=50K")
n_0 = length(idx_0)
idx_1 = which(y_train == ">50K")
n_1 = length(idx_1)

bootstrap_indices = list()
for (m in 1 : num_trees){
  bootstrap_indices[[m]] = c( #note n_0' + n_1' doesn't equal n. You can make it so with one more line of code...
    sample(idx_0, round(2.0 * n_0), replace = TRUE),
    sample(idx_1, round(0.5 * n_1), replace = TRUE)
  )
}
yarf_mod_asymmetric = YARF(X_train, y_train, bootstrap_indices = bootstrap_indices, calculate_oob_error = FALSE)
y_hat_test = predict(yarf_mod_asymmetric, X_test)
oos_confusion = table(y_test, y_hat_test)
oos_confusion
cat("FDR =", oos_confusion[1, 2] / sum(oos_confusion[, 2]), "\n")
cat("FOR =", oos_confusion[2, 1] / sum(oos_confusion[, 1]), "\n")
```

You can even vary the sampling and trace out ROC / DET curves. See function `YARFROC`.

# Boosting?

Nice simple explanation: https://towardsdatascience.com/basic-ensemble-learning-random-forest-adaboost-gradient-boosting-step-by-step-explained-95d49d1e2725

```{r}
pacman::p_load(xgboost)
```

Look at performance on adult dataset. This demo isn't working yet.

```{r}
xgboost_mod = xgboost(data = data.matrix(X_train), 
 label = as.numeric(y_train == ">50K"), 
 num_class = 2, #y = 0 or 1
 eta = 0.3, #default
 max_depth = 6, #default 
 nrounds = 25, 
 subsample = 1, #default 
 colsample_bytree = 1,
 eval_metric = "merror",
 objective = "multi:softmax",
 nthread = 3
)

y_hat_test = as.numeric(predict(xgboost_mod, data.matrix(X_test)))
oos_confusion = table(y_test, ifelse(y_hat_test == 0, "<=50K", ">50K"))
oos_confusion
cat("FDR =", oos_confusion[1, 2] / sum(oos_confusion[, 2]), "\n")
cat("FOR =", oos_confusion[2, 1] / sum(oos_confusion[, 1]), "\n")
```

Invert train and test splits and let it train on 28,000 observations.

```{r}
xgboost_mod = xgboost(data = data.matrix(X_test), 
 label = as.numeric(y_test == ">50K"), 
 num_class = 2, #y = 0 or 1
 eta = 0.5, #default
 max_depth = 6, #default 
 nrounds = 50, 
 subsample = 1, #default 
 colsample_bytree = 1,
 eval_metric = "merror",
 objective = "multi:softmax",
 nthread = 3
)

y_hat_test = as.numeric(predict(xgboost_mod, data.matrix(X_train)))
oos_confusion = table(y_train, ifelse(y_hat_test == 0, "<=50K", ">50K"))
oos_confusion
cat("FDR =", oos_confusion[1, 2] / sum(oos_confusion[, 2]), "\n")
cat("FOR =", oos_confusion[2, 1] / sum(oos_confusion[, 1]), "\n")
```

Lightning fast on $n = 30000$!!! But only a bit more accurate. This leads me to think the error is mostly in delta.

We can try playing with the hyperparams. A lot to CV over! You think this is a lot... wait until you see deep learning networks!



